var __awaiter=this&&this.__awaiter||function(thisArg,_arguments,P,generator){return new(P||(P=Promise))((function(resolve,reject){function fulfilled(value){try{step(generator.next(value))}catch(e){reject(e)}}function rejected(value){try{step(generator.throw(value))}catch(e){reject(e)}}function step(result){result.done?resolve(result.value):function adopt(value){return value instanceof P?value:new P((function(resolve){resolve(value)}))}(result.value).then(fulfilled,rejected)}step((generator=generator.apply(thisArg,_arguments||[])).next())}))};import*as strings from"../../../base/common/strings.js";import{LineTokens}from"../tokens/lineTokens.js";import{TokenizationRegistry}from"../languages.js";import{NullState,nullTokenizeEncoded}from"./nullTokenize.js";const fallback={getInitialState:()=>NullState,tokenizeEncoded:(buffer,hasEOL,state)=>nullTokenizeEncoded(0,state)};export function tokenizeToString(languageService,text,languageId){return __awaiter(this,void 0,void 0,(function*(){if(!languageId)return _tokenizeToString(text,languageService.languageIdCodec,fallback);const tokenizationSupport=yield TokenizationRegistry.getOrCreate(languageId);return _tokenizeToString(text,languageService.languageIdCodec,tokenizationSupport||fallback)}))}export function tokenizeLineToHTML(text,viewLineTokens,colorMap,startOffset,endOffset,tabSize,useNbsp){let result="<div>",charIndex=startOffset,tabsCharDelta=0,prevIsSpace=!0;for(let tokenIndex=0,tokenCount=viewLineTokens.getCount();tokenIndex<tokenCount;tokenIndex++){const tokenEndIndex=viewLineTokens.getEndOffset(tokenIndex);if(tokenEndIndex<=startOffset)continue;let partContent="";for(;charIndex<tokenEndIndex&&charIndex<endOffset;charIndex++){const charCode=text.charCodeAt(charIndex);switch(charCode){case 9:{let insertSpacesCount=tabSize-(charIndex+tabsCharDelta)%tabSize;for(tabsCharDelta+=insertSpacesCount-1;insertSpacesCount>0;)useNbsp&&prevIsSpace?(partContent+="&#160;",prevIsSpace=!1):(partContent+=" ",prevIsSpace=!0),insertSpacesCount--;break}case 60:partContent+="&lt;",prevIsSpace=!1;break;case 62:partContent+="&gt;",prevIsSpace=!1;break;case 38:partContent+="&amp;",prevIsSpace=!1;break;case 0:partContent+="&#00;",prevIsSpace=!1;break;case 65279:case 8232:case 8233:case 133:partContent+="ï¿½",prevIsSpace=!1;break;case 13:partContent+="&#8203",prevIsSpace=!1;break;case 32:useNbsp&&prevIsSpace?(partContent+="&#160;",prevIsSpace=!1):(partContent+=" ",prevIsSpace=!0);break;default:partContent+=String.fromCharCode(charCode),prevIsSpace=!1}}if(result+=`<span style="${viewLineTokens.getInlineStyle(tokenIndex,colorMap)}">${partContent}</span>`,tokenEndIndex>endOffset||charIndex>=endOffset)break}return result+="</div>",result}export function _tokenizeToString(text,languageIdCodec,tokenizationSupport){let result='<div class="monaco-tokenized-source">';const lines=strings.splitLines(text);let currentState=tokenizationSupport.getInitialState();for(let i=0,len=lines.length;i<len;i++){const line=lines[i];i>0&&(result+="<br/>");const tokenizationResult=tokenizationSupport.tokenizeEncoded(line,!0,currentState);LineTokens.convertToEndOffset(tokenizationResult.tokens,line.length);const viewLineTokens=new LineTokens(tokenizationResult.tokens,line,languageIdCodec).inflate();let startOffset=0;for(let j=0,lenJ=viewLineTokens.getCount();j<lenJ;j++){const type=viewLineTokens.getClassName(j),endIndex=viewLineTokens.getEndOffset(j);result+=`<span class="${type}">${strings.escape(line.substring(startOffset,endIndex))}</span>`,startOffset=endIndex}currentState=tokenizationResult.endState}return result+="</div>",result}