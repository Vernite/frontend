import{NotSupportedError}from"../../../../../base/common/errors.js";import{TokenMetadata}from"../../../encodedTokenAttributes.js";import{TextAstNode}from"./ast.js";import{lengthAdd,lengthDiff,lengthGetColumnCountIfZeroLineCount,lengthToObj,lengthZero,toLength}from"./length.js";import{SmallImmutableSet}from"./smallImmutableSet.js";export class Token{constructor(length,kind,bracketId,bracketIds,astNode){this.length=length,this.kind=kind,this.bracketId=bracketId,this.bracketIds=bracketIds,this.astNode=astNode}}export class TextBufferTokenizer{constructor(textModel,bracketTokens){this.textModel=textModel,this.bracketTokens=bracketTokens,this.reader=new NonPeekableTextBufferTokenizer(this.textModel,this.bracketTokens),this._offset=lengthZero,this.didPeek=!1,this.peeked=null,this.textBufferLineCount=textModel.getLineCount(),this.textBufferLastLineLength=textModel.getLineLength(this.textBufferLineCount)}get offset(){return this._offset}get length(){return toLength(this.textBufferLineCount,this.textBufferLastLineLength)}skip(length){this.didPeek=!1,this._offset=lengthAdd(this._offset,length);const obj=lengthToObj(this._offset);this.reader.setPosition(obj.lineCount,obj.columnCount)}read(){let token;return this.peeked?(this.didPeek=!1,token=this.peeked):token=this.reader.read(),token&&(this._offset=lengthAdd(this._offset,token.length)),token}peek(){return this.didPeek||(this.peeked=this.reader.read(),this.didPeek=!0),this.peeked}}class NonPeekableTextBufferTokenizer{constructor(textModel,bracketTokens){this.textModel=textModel,this.bracketTokens=bracketTokens,this.lineIdx=0,this.line=null,this.lineCharOffset=0,this.lineTokens=null,this.lineTokenOffset=0,this.peekedToken=null,this.textBufferLineCount=textModel.getLineCount(),this.textBufferLastLineLength=textModel.getLineLength(this.textBufferLineCount)}setPosition(lineIdx,column){lineIdx===this.lineIdx?(this.lineCharOffset=column,this.lineTokenOffset=0===this.lineCharOffset?0:this.lineTokens.findTokenIndexAtOffset(this.lineCharOffset)):(this.lineIdx=lineIdx,this.lineCharOffset=column,this.line=null),this.peekedToken=null}read(){if(this.peekedToken){const token=this.peekedToken;return this.peekedToken=null,this.lineCharOffset+=lengthGetColumnCountIfZeroLineCount(token.length),token}if(this.lineIdx>this.textBufferLineCount-1||this.lineIdx===this.textBufferLineCount-1&&this.lineCharOffset>=this.textBufferLastLineLength)return null;null===this.line&&(this.lineTokens=this.textModel.tokenization.getLineTokens(this.lineIdx+1),this.line=this.lineTokens.getLineContent(),this.lineTokenOffset=0===this.lineCharOffset?0:this.lineTokens.findTokenIndexAtOffset(this.lineCharOffset));const startLineIdx=this.lineIdx,startLineCharOffset=this.lineCharOffset;let lengthHeuristic=0;for(;;){const lineTokens=this.lineTokens,tokenCount=lineTokens.getCount();let peekedBracketToken=null;if(this.lineTokenOffset<tokenCount){const tokenMetadata=lineTokens.getMetadata(this.lineTokenOffset);for(;this.lineTokenOffset+1<tokenCount&&tokenMetadata===lineTokens.getMetadata(this.lineTokenOffset+1);)this.lineTokenOffset++;const isOther=0===TokenMetadata.getTokenType(tokenMetadata),containsBracketType=TokenMetadata.containsBalancedBrackets(tokenMetadata),endOffset=lineTokens.getEndOffset(this.lineTokenOffset);if(containsBracketType&&isOther&&this.lineCharOffset<endOffset){const languageId=lineTokens.getLanguageId(this.lineTokenOffset),text=this.line.substring(this.lineCharOffset,endOffset),brackets=this.bracketTokens.getSingleLanguageBracketTokens(languageId),regexp=brackets.regExpGlobal;if(regexp){regexp.lastIndex=0;const match=regexp.exec(text);match&&(peekedBracketToken=brackets.getToken(match[0]),peekedBracketToken&&(this.lineCharOffset+=match.index))}}if(lengthHeuristic+=endOffset-this.lineCharOffset,peekedBracketToken){if(startLineIdx!==this.lineIdx||startLineCharOffset!==this.lineCharOffset){this.peekedToken=peekedBracketToken;break}return this.lineCharOffset+=lengthGetColumnCountIfZeroLineCount(peekedBracketToken.length),peekedBracketToken}this.lineTokenOffset++,this.lineCharOffset=endOffset}else{if(this.lineIdx===this.textBufferLineCount-1)break;if(this.lineIdx++,this.lineTokens=this.textModel.tokenization.getLineTokens(this.lineIdx+1),this.lineTokenOffset=0,this.line=this.lineTokens.getLineContent(),this.lineCharOffset=0,lengthHeuristic+=33,lengthHeuristic>1e3)break}if(lengthHeuristic>1500)break}const length=lengthDiff(startLineIdx,startLineCharOffset,this.lineIdx,this.lineCharOffset);return new Token(length,0,-1,SmallImmutableSet.getEmpty(),new TextAstNode(length))}}export class FastTokenizer{constructor(text,brackets){this.text=text,this._offset=lengthZero,this.idx=0;const regExpStr=brackets.getRegExpStr(),regexp=regExpStr?new RegExp(regExpStr+"|\n","gi"):null,tokens=[];let match,curLineCount=0,lastLineBreakOffset=0,lastTokenEndOffset=0,lastTokenEndLine=0;const smallTextTokens0Line=new Array;for(let i=0;i<60;i++)smallTextTokens0Line.push(new Token(toLength(0,i),0,-1,SmallImmutableSet.getEmpty(),new TextAstNode(toLength(0,i))));const smallTextTokens1Line=new Array;for(let i=0;i<60;i++)smallTextTokens1Line.push(new Token(toLength(1,i),0,-1,SmallImmutableSet.getEmpty(),new TextAstNode(toLength(1,i))));if(regexp)for(regexp.lastIndex=0;null!==(match=regexp.exec(text));){const curOffset=match.index,value=match[0];if("\n"===value)curLineCount++,lastLineBreakOffset=curOffset+1;else{if(lastTokenEndOffset!==curOffset){let token;if(lastTokenEndLine===curLineCount){const colCount=curOffset-lastTokenEndOffset;if(colCount<smallTextTokens0Line.length)token=smallTextTokens0Line[colCount];else{const length=toLength(0,colCount);token=new Token(length,0,-1,SmallImmutableSet.getEmpty(),new TextAstNode(length))}}else{const lineCount=curLineCount-lastTokenEndLine,colCount=curOffset-lastLineBreakOffset;if(1===lineCount&&colCount<smallTextTokens1Line.length)token=smallTextTokens1Line[colCount];else{const length=toLength(lineCount,colCount);token=new Token(length,0,-1,SmallImmutableSet.getEmpty(),new TextAstNode(length))}}tokens.push(token)}tokens.push(brackets.getToken(value)),lastTokenEndOffset=curOffset+value.length,lastTokenEndLine=curLineCount}}const offset=text.length;if(lastTokenEndOffset!==offset){const length=lastTokenEndLine===curLineCount?toLength(0,offset-lastTokenEndOffset):toLength(curLineCount-lastTokenEndLine,offset-lastLineBreakOffset);tokens.push(new Token(length,0,-1,SmallImmutableSet.getEmpty(),new TextAstNode(length)))}this.length=toLength(curLineCount,offset-lastLineBreakOffset),this.tokens=tokens}get offset(){return this._offset}read(){return this.tokens[this.idx++]||null}peek(){return this.tokens[this.idx]||null}skip(length){throw new NotSupportedError}}